{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "pd.set_option('display.max_columns', None) # display all columns in DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Metastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://data.medicaid.gov/api/1/metastore/schemas/dataset/items') # requesting meta data\n",
    "data = r.json()\n",
    "\n",
    "df_metastore = pd.json_normalize(data, max_level = 1)\n",
    "df_metastore = df_metastore[df_metastore['title'].str.contains('State Drug Utilization Data')] # selecting datasets\n",
    "df_metastore = df_metastore.sort_values(['title']) # sorting datasets\n",
    "df_metastore['year'] = df_metastore['title'].str[-4:] # creating variable for year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data from Medicaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Drug Utilization Data 1999\n",
      "State Drug Utilization Data 2000\n",
      "State Drug Utilization Data 2001\n",
      "State Drug Utilization Data 2002\n",
      "State Drug Utilization Data 2003\n",
      "State Drug Utilization Data 2004\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-23a5dc8ac4b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0moffset_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'?offset='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmiddle_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mend_url\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# requesting part of dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m                 \u001b[0mdf_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'results'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_level\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mjson\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    896\u001b[0m                     \u001b[1;31m# used.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    899\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 357\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "start_year = 1999\n",
    "\n",
    "for index, row in df_metastore.iterrows(): # iterating through meta data\n",
    "\n",
    "    title_i = df_metastore['title'][index]\n",
    "    identifier_i = df_metastore['identifier'][index]\n",
    "    year_i = df_metastore['year'][index]\n",
    "\n",
    "    if int(year_i) >= start_year: # selecting meta data from start year and onward\n",
    "        \n",
    "        print(title_i)\n",
    "        \n",
    "        start_url = 'https://data.medicaid.gov/api/1/datastore/query/'\n",
    "        middle_url = str(identifier_i)\n",
    "        end_url = '/0'\n",
    "        \n",
    "        r = requests.get(start_url + middle_url + end_url, timeout = 20)  # requesting part of dataset\n",
    "        data = r.json()\n",
    "        \n",
    "        data_n = data['count'] # finding the number of observations\n",
    "        \n",
    "        for offset_i in range(0, int(data_n), 10000): # iterating through data in smaller \n",
    "    \n",
    "            if offset_i == 0:\n",
    "\n",
    "                df_temp = pd.json_normalize(data['results'], max_level = 1)\n",
    "                \n",
    "                df_temp['units_reimbursed'] = pd.to_numeric(df_temp['units_reimbursed'], errors='coerce') # removing empty observations\n",
    "                df_temp['total_amount_reimbursed'] = pd.to_numeric(df_temp['total_amount_reimbursed'], errors='coerce')\n",
    "                df_temp.dropna(subset = ['units_reimbursed', 'total_amount_reimbursed'], inplace = True)\n",
    "\n",
    "                df_temp = df_temp[(df_temp['units_reimbursed'] != 0)] # removing zero observations\n",
    "                df_temp = df_temp[(df_temp['total_amount_reimbursed'] != 0)]\n",
    "                \n",
    "            else:\n",
    "                offset = offset_i\n",
    "                offset_url = '?offset=' + str(offset)\n",
    "                r = requests.get(start_url + middle_url + end_url + offset_url, timeout = 20) # requesting part of dataset\n",
    "                data = r.json()\n",
    "                \n",
    "                df_temp = pd.json_normalize(data['results'], max_level = 1)\n",
    "                \n",
    "                df_temp['units_reimbursed'] = pd.to_numeric(df_temp['units_reimbursed'], errors='coerce') # removing empty observations\n",
    "                df_temp['total_amount_reimbursed'] = pd.to_numeric(df_temp['total_amount_reimbursed'], errors='coerce')\n",
    "                df_temp.dropna(subset = ['units_reimbursed', 'total_amount_reimbursed'], inplace = True)\n",
    "\n",
    "                df_temp = df_temp[(df_temp['units_reimbursed'] != 0)] # removing zero observations\n",
    "                df_temp = df_temp[(df_temp['total_amount_reimbursed'] != 0)]\n",
    "\n",
    "            if offset_i == 0:\n",
    "                df = df_temp\n",
    "            else:\n",
    "                df = df.append(df_temp, ignore_index = True)\n",
    "        \n",
    "    if int(year_i) == start_year:\n",
    "        df['dataset'] = title_i # adding name of dataset\n",
    "        \n",
    "        df['price_per_unit'] = df['total_amount_reimbursed'] / df['units_reimbursed'] # calculating price per unit\n",
    "        df_price_per_unit = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['price_per_unit'].mean() # grouping by for each NDA and year    \n",
    "        df_units_reimbursed = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['units_reimbursed'].sum()\n",
    "        df_total_amount_reimbursed = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['total_amount_reimbursed'].sum()\n",
    "        \n",
    "        df_temp = pd.merge(df_price_per_unit, df_units_reimbursed, left_index = True, right_index = True)\n",
    "        df_medicaid = pd.merge(df_temp, df_total_amount_reimbursed, left_index = True, right_index = True)\n",
    "        \n",
    "        df_medicaid = df_medicaid.reset_index()\n",
    "\n",
    "    elif int(year_i) >= start_year:\n",
    "        df['dataset'] = title_i # adding name of dataset\n",
    "        \n",
    "        df['price_per_unit'] = df['total_amount_reimbursed'] / df['units_reimbursed'] # calculating price per unit\n",
    "        df_price_per_unit = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['price_per_unit'].mean() # grouping by for each NDA and year    \n",
    "        df_units_reimbursed = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['units_reimbursed'].sum()\n",
    "        df_total_amount_reimbursed = df.groupby(['dataset', 'labeler_code', 'product_code', 'year', 'quarter'])['total_amount_reimbursed'].sum()\n",
    "        \n",
    "        df_temp = pd.merge(df_price_per_unit, df_units_reimbursed, left_index = True, right_index = True)\n",
    "        df_medicaid = pd.merge(df_temp, df_total_amount_reimbursed, left_index = True, right_index = True)\n",
    "        \n",
    "        df = df_medicaid.reset_index()\n",
    "        \n",
    "        df_medicaid = df_medicaid.append(df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medicaid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medicaid.to_csv('raw_medicaid_data.csv', index = False)\n",
    "#df_medicaid.to_excel('raw_medicaid_data.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
