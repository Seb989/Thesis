{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # removing some warnings\n",
    "pd.set_option('display.max_columns', None) # display all columns in DF\n",
    "import datetime as dt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "\n",
    "from linearmodels import PooledOLS\n",
    "import statsmodels.api as sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_org = pd.read_csv('raw_consolidation_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>marketing_category</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>generic_name</th>\n",
       "      <th>labeler_name</th>\n",
       "      <th>pharm_class</th>\n",
       "      <th>is_original_packager</th>\n",
       "      <th>units_reimbursed</th>\n",
       "      <th>total_amount_reimbursed_adj</th>\n",
       "      <th>price_per_unit_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>acetaminophen-tablet-oral-300 mg/1</td>\n",
       "      <td>ANDA</td>\n",
       "      <td>Acetaminophen and Codeine Phosphate</td>\n",
       "      <td>ACETAMINOPHEN</td>\n",
       "      <td>Teva Pharmaceuticals USA, Inc.</td>\n",
       "      <td>['Full Opioid Agonists [MoA]', 'Opioid Agonist...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.599944e+06</td>\n",
       "      <td>1.554268e+06</td>\n",
       "      <td>0.604724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1991-01-01</td>\n",
       "      <td>acetaminophen-tablet-oral-325 mg/1</td>\n",
       "      <td>ANDA</td>\n",
       "      <td>butalbital, acetaminophen and caffeine</td>\n",
       "      <td>ACETAMINOPHEN</td>\n",
       "      <td>Mikart, LLC</td>\n",
       "      <td>['Barbiturate [EPC]', 'Barbiturates [CS]', 'Ce...</td>\n",
       "      <td>True</td>\n",
       "      <td>2.762276e+05</td>\n",
       "      <td>1.785151e+05</td>\n",
       "      <td>0.646261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                           unique_id marketing_category  \\\n",
       "0  1991-01-01  acetaminophen-tablet-oral-300 mg/1               ANDA   \n",
       "1  1991-01-01  acetaminophen-tablet-oral-325 mg/1               ANDA   \n",
       "\n",
       "                               brand_name   generic_name  \\\n",
       "0     Acetaminophen and Codeine Phosphate  ACETAMINOPHEN   \n",
       "1  butalbital, acetaminophen and caffeine  ACETAMINOPHEN   \n",
       "\n",
       "                     labeler_name  \\\n",
       "0  Teva Pharmaceuticals USA, Inc.   \n",
       "1                     Mikart, LLC   \n",
       "\n",
       "                                         pharm_class  is_original_packager  \\\n",
       "0  ['Full Opioid Agonists [MoA]', 'Opioid Agonist...                  True   \n",
       "1  ['Barbiturate [EPC]', 'Barbiturates [CS]', 'Ce...                  True   \n",
       "\n",
       "   units_reimbursed  total_amount_reimbursed_adj  price_per_unit_adj  \n",
       "0      2.599944e+06                 1.554268e+06            0.604724  \n",
       "1      2.762276e+05                 1.785151e+05            0.646261  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg_org.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing labeller that are original packager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg_org.loc[df_reg_org['is_original_packager'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551764\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning order of entrance for each unique drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.sort_values(by = ['unique_id', 'date', 'marketing_category'], ascending = [False, True, False], ignore_index = True) # Sorting\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'labeler_name'], keep = 'first') # Finding the first entrance for each labeller \n",
    "\n",
    "df_temp['labeler_name_count'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'labeler_name', 'labeler_name_count']], df_reg, on = ['unique_id', 'labeler_name'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for first entrance and NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['labeler_name_count'] == 1) & (df_reg['marketing_category'] == 'NDA')] # Filtering\n",
    "\n",
    "df_temp = df_temp.sort_values(by = ['date', 'unique_id'], ascending = [True, False], ignore_index = True) # Sorting\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['first_nda'] = 1 # Adding dummy\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'first_nda']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['first_nda'] = df_reg['first_nda'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug where the first entrance is not a NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['first_nda'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] == 1]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['running_count_from_start'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_start']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['running_count_from_second_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_second_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_second_entrance'] = df_reg['running_count_from_second_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a total count of the labelers at the start (to exclude unique drug with multiple labelers from the start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['running_count_from_start'] == 1)]\n",
    "          \n",
    "df_temp = df_temp.groupby(['unique_id'])['first_nda'].sum()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.rename(columns = {\"first_nda\": \"number_of_first_entrance\"})\n",
    "\n",
    "df_temp = df_temp.loc[(df_temp['number_of_first_entrance'] > 1)]\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'number_of_first_entrance']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['number_of_first_entrance'] = df_reg['number_of_first_entrance'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug which has multiple entrances at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['number_of_first_entrance'] == 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of generic labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'labeler_name', 'labeler_name_count']]\n",
    "\n",
    "df_temp = df_temp.groupby(['date', 'unique_id'])\n",
    "\n",
    "df_temp = df_temp.max()\n",
    "\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_generics'] = df_temp['labeler_name_count'] - 1 # Minus by one because org. labeler do not count\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_generics']], df_reg, on = ['date', 'unique_id'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of substitutes labelers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking pharm class to obtain EPC and MoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(df_reg[['unique_id', 'pharm_class']])\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'pharm_class'])\n",
    "\n",
    "df_temp['pharm_class'] = df_temp['pharm_class'].apply(literal_eval)\n",
    "df_temp = df_temp.explode('pharm_class')\n",
    "\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class'].apply(lambda x: str(x)[-5:])\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class_type'].str.replace(r'[][]', '', regex=True)\n",
    "\n",
    "df_temp_EPC = df_temp[df_temp['pharm_class_type'] == 'EPC']\n",
    "df_temp_MoA = df_temp[df_temp['pharm_class_type'] == 'MoA']\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.rename(columns = {\"pharm_class\": \"pharm_class_EPC\"})\n",
    "df_temp_MoA = df_temp_MoA.rename(columns = {\"pharm_class\": \"pharm_class_MoA\"})\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.drop_duplicates(subset = ['unique_id', 'pharm_class_EPC'])\n",
    "df_temp_MoA = df_temp_MoA.drop_duplicates(subset = ['unique_id', 'pharm_class_MoA'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_temp_EPC, df_temp_MoA,  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openFDA_NDC = pd.read_csv('raw_openFDA_NDC_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_openFDA_NDC.drop_duplicates(subset = ['unique_id'])\n",
    "df_pharm_class_type = pd.merge(df_pharm_class_type, df_temp[['unique_id', 'route']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a unique id for substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharm_class_type['unique_substitute'] = df_pharm_class_type['pharm_class_EPC'].astype(str) + '-' + df_pharm_class_type['route'].astype(str) + '-' + df_pharm_class_type['pharm_class_MoA'].astype(str)\n",
    "df_pharm_class_type = df_pharm_class_type[['unique_id', 'unique_substitute']]\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.drop_duplicates(subset = ['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_reg, df_pharm_class_type[['unique_id', 'unique_substitute']],  on = 'unique_id', how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['date', 'unique_substitute'])['unique_id'].count()\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_unique_substitute'] = df_temp['unique_id'] - 1\n",
    "\n",
    "df_reg = pd.merge(df_reg, df_temp[['date', 'unique_substitute', 'running_count_unique_substitute']],  on = ['date', 'unique_substitute'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the quarterly total amount reimbursed and units reimbursed for all labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'units_reimbursed_sum', 'total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the generic labelers' share of quarterly total amount reimbursed and units reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"generic_units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"generic_total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'generic_units_reimbursed_sum', 'generic_total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['generic_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'] / df_reg['units_reimbursed_sum']\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'] / df_reg['total_amount_reimbursed_adj_sum']\n",
    "\n",
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_share_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_share_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225135\n",
      "225135\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))\n",
    "df_reg_issue = df_reg.drop_duplicates(subset = ['unique_id', 'date', 'labeler_name'])\n",
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv('output_regression_org.csv', sep = '~', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv('output_regression_org.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for generic paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225135"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_reg\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on orig. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139197"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_temp[df_temp['marketing_category'] == \"NDA\"]\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of price per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_price_per_unit_adj'] = np.log(df_temp['price_per_unit_adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the share of units reimbursed for the org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['org_share_units_reimbursed_sum'] = 1 - df_temp['generic_share_units_reimbursed_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date_int'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date_int'] = df_temp['date_int'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS_ndc_gp = df_temp.set_index(['unique_id', 'date_int'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            PooledOLS Estimation Summary                           \n",
      "===================================================================================\n",
      "Dep. Variable:     ln_price_per_unit_adj   R-squared:                        0.0314\n",
      "Estimator:                     PooledOLS   R-squared (Between):             -0.0019\n",
      "No. Observations:                 136950   R-squared (Within):              -0.1151\n",
      "Date:                   Sun, Mar 13 2022   R-squared (Overall):              0.0314\n",
      "Time:                           10:42:55   Log-likelihood                -3.142e+05\n",
      "Cov. Estimator:               Unadjusted                                           \n",
      "                                           F-statistic:                      1108.4\n",
      "Entities:                           2951   P-value                           0.0000\n",
      "Avg Obs:                          46.408   Distribution:                F(4,136945)\n",
      "Min Obs:                          1.0000                                           \n",
      "Max Obs:                          421.00   F-statistic (robust):             1108.4\n",
      "                                           P-value                           0.0000\n",
      "Time periods:                        121   Distribution:                F(4,136945)\n",
      "Avg Obs:                          1131.8                                           \n",
      "Min Obs:                          141.00                                           \n",
      "Max Obs:                          2698.0                                           \n",
      "                                                                                   \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  2.2673     0.0317     71.445     0.0000      2.2051      2.3295\n",
      "running_count_generics                 0.1846     0.0051     35.934     0.0000      0.1745      0.1946\n",
      "running_count_unique_substitute       -0.0074     0.0001    -57.946     0.0000     -0.0076     -0.0071\n",
      "org_share_units_reimbursed_sum        -0.2950     0.0325    -9.0848     0.0000     -0.3586     -0.2313\n",
      "running_count_from_second_entrance    -0.0227     0.0007    -31.025     0.0000     -0.0241     -0.0212\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "endog = df_OLS_ndc_gp['ln_price_per_unit_adj']\n",
    "exog_vars = ['running_count_generics', 'running_count_unique_substitute', 'org_share_units_reimbursed_sum', 'running_count_from_second_entrance']\n",
    "exog = sm.add_constant(df_OLS_ndc_gp[exog_vars])\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        141\n",
      "1  1991-04-01        156\n",
      "2  1991-07-01        164\n",
      "3  1991-10-01        185\n",
      "4  1992-01-01        204\n",
      "Quarterly Average:  1150.388429752066\n",
      "Total:  3012\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for probability of entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['second_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df_temp['second_entrance'] = df_temp['second_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date'] = df_temp['date'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                        0.0005\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2420\n",
      "No. Observations:              229525   R-squared (Within):              -0.0015\n",
      "Date:                Wed, Mar 09 2022   R-squared (Overall):              0.0005\n",
      "Time:                        09:39:24   Log-likelihood                -7.596e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      119.34\n",
      "Entities:                        3582   P-value                           0.0000\n",
      "Avg Obs:                       64.077   Distribution:                F(1,229523)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       612.00   F-statistic (robust):             119.34\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                     121   Distribution:                F(1,229523)\n",
      "Avg Obs:                       1896.9                                           \n",
      "Min Obs:                       182.00                                           \n",
      "Max Obs:                       6383.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.0916     0.0036     25.198     0.0000      0.0845      0.0988\n",
      "ln_total_amount_reimbursed_adj_sum     0.0029     0.0003     10.924     0.0000      0.0023      0.0034\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
