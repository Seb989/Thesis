{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # removing some warnings\n",
    "pd.set_option('display.max_columns', None) # display all columns in DF\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "import seaborn as sns\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (26,27,28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_reg_org = pd.read_csv('raw_consolidation_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg_org.loc[df_reg_org['is_original_packager'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515574"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        544\n",
      "1  1991-04-01        568\n",
      "2  1991-07-01        580\n",
      "3  1991-10-01        582\n",
      "4  1992-01-01        612\n",
      "Quarterly Average:  4260.94214876033\n",
      "Total:  7214\n",
      "Total (generic_name):  2117\n",
      "Total (labeler):  567\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())\n",
    "print('Total (generic_name): ', df_temp['generic_name'].nunique())\n",
    "print('Total (labeler): ', df_temp['labeler_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing labeller that are original packager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515574\n",
      "496657\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg_org))\n",
    "df_reg = df_reg_org.loc[df_reg_org['is_original_packager'] == True]\n",
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning order of entrance for each unique drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.sort_values(by = ['unique_id', 'date', 'marketing_category'], ascending = [False, True, False], ignore_index = True) # Sorting\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'labeler_name'], keep = 'first') # Finding the first entrance for each labeller \n",
    "\n",
    "df_temp['labeler_name_count'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'labeler_name', 'labeler_name_count']], df_reg, on = ['unique_id', 'labeler_name'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496657\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for first entrance and NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['labeler_name_count'] == 1) & (df_reg['marketing_category'] == 'NDA')] # Filtering\n",
    "\n",
    "df_temp = df_temp.sort_values(by = ['date', 'unique_id'], ascending = [True, False], ignore_index = True) # Sorting\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['first_nda'] = 1 # Adding dummy\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'first_nda']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['first_nda'] = df_reg['first_nda'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "496657\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug where the first entrance is not a NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['first_nda'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201875"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_start'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_start']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201875"
      ]
     },
     "execution_count": 1055,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assigning a running count for each unique drug from second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_second_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_second_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_second_entrance'] = df_reg['running_count_from_second_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201875"
      ]
     },
     "execution_count": 1057,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assigning a total count of the labelers at the start (to exclude unique drug with multiple labelers from the start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['running_count_from_start'] == 1)]\n",
    "          \n",
    "df_temp = df_temp.groupby(['unique_id'])['first_nda'].sum()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.rename(columns = {\"first_nda\": \"number_of_first_entrance\"})\n",
    "\n",
    "df_temp = df_temp.loc[(df_temp['number_of_first_entrance'] > 1)]\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'number_of_first_entrance']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['number_of_first_entrance'] = df_reg['number_of_first_entrance'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug which has multiple entrances at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['number_of_first_entrance'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193215"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of generic labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'labeler_name', 'labeler_name_count']]\n",
    "\n",
    "df_temp = df_temp.groupby(['date', 'unique_id'])\n",
    "\n",
    "df_temp = df_temp.max()\n",
    "\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_generics'] = df_temp['labeler_name_count'] - 1 # Minus by one because org. labeler do not count\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_generics']], df_reg, on = ['date', 'unique_id'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Assigning dummies for generic entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id']]\n",
    "df_temp['labeler_name_count_2_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 0)  else 0)\n",
    "df_temp['labeler_name_count_3_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 1)  else 0)\n",
    "df_temp['labeler_name_count_4_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 2)  else 0)\n",
    "df_temp['labeler_name_count_5_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 3)  else 0)\n",
    "df_temp['labeler_name_count_6_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 4)  else 0)\n",
    "df_temp['labeler_name_count_7_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 5)  else 0)\n",
    "df_temp['labeler_name_count_8_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 6)  else 0)\n",
    "df_temp['labeler_name_count_9_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 7)  else 0)\n",
    "df_temp['labeler_name_count_10_dummy'] = df_reg['running_count_generics'].apply(lambda x: 1 if (x > 8)  else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp/ipykernel_3480/3182860570.py:1: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_temp = df_temp.groupby(['date', 'unique_id'], as_index = False)['labeler_name_count_2_dummy', 'labeler_name_count_3_dummy', 'labeler_name_count_4_dummy', 'labeler_name_count_5_dummy', 'labeler_name_count_6_dummy', 'labeler_name_count_7_dummy', 'labeler_name_count_8_dummy', 'labeler_name_count_9_dummy', 'labeler_name_count_10_dummy'].sum()\n"
     ]
    }
   ],
   "source": [
    "df_temp = df_temp.groupby(['date', 'unique_id'], as_index = False)['labeler_name_count_2_dummy', 'labeler_name_count_3_dummy', 'labeler_name_count_4_dummy', 'labeler_name_count_5_dummy', 'labeler_name_count_6_dummy', 'labeler_name_count_7_dummy', 'labeler_name_count_8_dummy', 'labeler_name_count_9_dummy', 'labeler_name_count_10_dummy'].sum()\n",
    "\n",
    "number = 0\n",
    "for (column_name, column_value) in df_temp.iteritems():\n",
    "    number = number + 1\n",
    "    if number > 2:\n",
    "        df_temp[column_name] = np.where(df_temp[column_name] >= 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'labeler_name_count_2_dummy', 'labeler_name_count_3_dummy', 'labeler_name_count_4_dummy', 'labeler_name_count_5_dummy', 'labeler_name_count_6_dummy', 'labeler_name_count_7_dummy', 'labeler_name_count_8_dummy', 'labeler_name_count_9_dummy', 'labeler_name_count_10_dummy']], df_reg, on = ['date', 'unique_id'], how = 'right') # Merging with reg. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193215"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of substitutes labelers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking pharm class to obtain EPC and MoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(df_reg[['unique_id', 'pharm_class']])\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'pharm_class'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['pharm_class'])\n",
    "df_temp['pharm_class'] = df_temp['pharm_class'].apply(literal_eval)\n",
    "df_temp = df_temp.explode('pharm_class')\n",
    "\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class'].apply(lambda x: str(x)[-5:])\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class_type'].str.replace(r'[][]', '', regex=True)\n",
    "\n",
    "df_temp_EPC = df_temp[df_temp['pharm_class_type'] == 'EPC']\n",
    "df_temp_MoA = df_temp[df_temp['pharm_class_type'] == 'MoA']\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.rename(columns = {\"pharm_class\": \"pharm_class_EPC\"})\n",
    "df_temp_MoA = df_temp_MoA.rename(columns = {\"pharm_class\": \"pharm_class_MoA\"})\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.drop_duplicates(subset = ['unique_id', 'pharm_class_EPC'])\n",
    "df_temp_MoA = df_temp_MoA.drop_duplicates(subset = ['unique_id', 'pharm_class_MoA'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_temp_EPC, df_temp_MoA,  on = 'unique_id', how = 'left')\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.dropna(subset = ['pharm_class_EPC'])\n",
    "df_pharm_class_type = df_pharm_class_type.dropna(subset = ['pharm_class_MoA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openFDA_NDC = pd.read_csv('raw_openFDA_NDC_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_openFDA_NDC.drop_duplicates(subset = ['unique_id'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['route'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_pharm_class_type, df_temp[['unique_id', 'route']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding ATC (level 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ATC = pd.read_csv('raw_consolidation_data_for_ATC.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_ATC.drop_duplicates(subset = ['unique_id'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['ATC (level 2)'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_pharm_class_type, df_temp[['unique_id', 'ATC (level 2)']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a unique id for substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharm_class_type['unique_substitute'] = df_pharm_class_type['ATC (level 2)'].astype(str) + '-' + df_pharm_class_type['pharm_class_EPC'].astype(str) + '-' + df_pharm_class_type['route'].astype(str) + '-' + df_pharm_class_type['pharm_class_MoA'].astype(str)\n",
    "df_pharm_class_type = df_pharm_class_type[['unique_id', 'unique_substitute']]\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.drop_duplicates(subset = ['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_reg, df_pharm_class_type[['unique_id', 'unique_substitute']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['date', 'unique_substitute'])['unique_id'].agg('nunique')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_unique_substitute'] = df_temp['unique_id'] - 1\n",
    "\n",
    "df_reg = pd.merge(df_reg, df_temp[['date', 'unique_substitute', 'running_count_unique_substitute']],  on = ['date', 'unique_substitute'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193215"
      ]
     },
     "execution_count": 1074,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count where the first entrance is the starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the running count from the start for unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'running_count_from_start', 'running_count_from_second_entrance']]\n",
    "\n",
    "df_temp['col_temp'] = df_temp['running_count_from_second_entrance'].map(lambda x: True if (x == 1.0)  else False)\n",
    "\n",
    "df_temp = df_temp[df_temp['col_temp'] == True]\n",
    "df_temp = df_temp.drop(columns=['col_temp'])\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])\n",
    "df_temp = df_temp.rename(columns = {\"running_count_from_start\": \"col_temp\"})\n",
    "df_temp = df_temp[['unique_id', 'col_temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'col_temp']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculationg the running count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['col_temp'] = df_reg['col_temp'].fillna(0)\n",
    "df_reg['col_temp'] = df_reg['running_count_from_start'] - df_reg['col_temp']\n",
    "\n",
    "df_reg['running_count_event'] = df_reg['col_temp'].where(df_reg['col_temp'] != df_reg['running_count_from_start'])\n",
    "\n",
    "df_reg = df_reg.drop(columns=['col_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193215"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['unique_id']).agg({'running_count_event': [np.min,np.max]})\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.droplevel(0, axis=1) \n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"\": \"unique_id\", \"amin\": \"min_quarter_before_second_entrance\", \"amax\": \"max_quarter_before_second_entrance\"})\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'min_quarter_before_second_entrance', 'max_quarter_before_second_entrance']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for 2006 (change in Medicare which affect Medicaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['dummy_2006'] = df_reg['year'].apply(lambda x: 1 if x == 2006 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the quarterly total amount reimbursed and units reimbursed for all labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'units_reimbursed_sum', 'total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the generic labelers' share of quarterly total amount reimbursed and units reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"generic_units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"generic_total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'generic_units_reimbursed_sum', 'generic_total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['generic_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'] / df_reg['units_reimbursed_sum']\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'] / df_reg['total_amount_reimbursed_adj_sum']\n",
    "\n",
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_share_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_share_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv('output_regression_org.csv', sep = '~', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (48,49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_reg = pd.read_csv('output_regression_org.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193215"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        148\n",
      "1  1991-04-01        159\n",
      "2  1991-07-01        165\n",
      "3  1991-10-01        165\n",
      "4  1992-01-01        181\n",
      "Quarterly Average:  1596.8181818181818\n",
      "Total:  2886\n",
      "Total (generic_name):  1155\n",
      "Total (labeler):  441\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())\n",
    "print('Total (generic_name): ', df_temp['generic_name'].nunique())\n",
    "print('Total (labeler): ', df_temp['labeler_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputting data for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning a dummy for brand-name and generic price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['producer_type'] = df_temp['labeler_name_count'].apply(lambda x: 'Brand-name producer' if x == 1 else 'Generic producer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing brand-name drugs without competition based on \"running_count_event\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.dropna(subset = ['running_count_event'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.groupby(['date', 'year', 'quarter', 'unique_id', 'producer_type', 'running_count_event'], as_index = False)[['price_per_unit_adj']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivotting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.pivot(index = ['date', 'year', 'quarter', 'unique_id', 'running_count_event'], columns = 'producer_type')['price_per_unit_adj']\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.rename_axis(None, axis=1)\n",
    "df_temp = df_temp.rename(columns = {\"producer_type\": \"index\", \"Brand-name producer\": \"price_per_unit_adj_b\", \"Generic producer\": \"price_per_unit_adj_g\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional variable from org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3444: DtypeWarning: Columns (48,49) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_reg = pd.read_csv('output_regression_org.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_temp = df_reg[['date', 'unique_id', 'running_count_generics', 'running_count_unique_substitute', 'labeler_name_count_2_dummy', 'labeler_name_count_3_dummy', 'labeler_name_count_4_dummy', 'labeler_name_count_5_dummy', 'labeler_name_count_6_dummy', 'labeler_name_count_7_dummy', 'labeler_name_count_8_dummy', 'labeler_name_count_9_dummy', 'labeler_name_count_10_dummy', 'A01', 'A02', 'A03', 'A04', 'A05', 'A06', 'A07', 'A08', 'A10', 'A11', 'A12', 'A14', 'A16', 'B01', 'B02', 'B03', 'B05', 'B06', 'C01', 'C02', 'C03', 'C04', 'C05', 'C07', 'C08', 'C09', 'C10', 'D01', 'D04', 'D05', 'D06', 'D07', 'D08', 'D10', 'D11', 'G01', 'G02', 'G03', 'G04', 'H01', 'H02', 'H03', 'H04', 'H05', 'J01', 'J02', 'J04', 'J05', 'J06', 'L01', 'L02', 'L03', 'L04', 'M01', 'M03', 'M04', 'M05', 'M09', 'N01', 'N02', 'N03', 'N04', 'N05', 'N06', 'N07', 'P01', 'P02', 'P03', 'R01', 'R03', 'R05', 'R06', 'R07', 'S01', 'V03', 'V04', 'V08']]\n",
    "df_reg_temp = df_reg_temp.drop_duplicates(subset = ['date', 'unique_id'])\n",
    "df_reg_trans = pd.merge(df_temp, df_reg_temp, on = ['date', 'unique_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_trans.to_csv('output_regression_transform.csv', sep = '~', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_temp.to_stata('data_reg.dta', version=117)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Regression for generic paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_reg\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on orig. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118723"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_temp[df_temp['labeler_name_count'] == 1]\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48035"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing data NaN in running_count_event\n",
    "df_temp = df_temp.dropna(subset = ['running_count_event'])\n",
    "\n",
    "# Select the min. number of quarter before and after the entrance entrance\n",
    "df_temp = df_temp[df_temp['min_quarter_before_second_entrance'] <= -10] # including drugs with 10 or more quarters \n",
    "df_temp = df_temp[df_temp['max_quarter_before_second_entrance'] >= 10]\n",
    "\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of price per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_price_per_unit_adj'] = np.log(df_temp['price_per_unit_adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date_int'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date_int'] = df_temp['date_int'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS_ndc_gp = df_temp.set_index(['unique_id', 'date_int'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            PanelOLS Estimation Summary                            \n",
      "===================================================================================\n",
      "Dep. Variable:     ln_price_per_unit_adj   R-squared:                     9.495e-06\n",
      "Estimator:                      PanelOLS   R-squared (Between):             -0.0067\n",
      "No. Observations:                  48035   R-squared (Within):              -0.0021\n",
      "Date:                   Thu, Mar 24 2022   R-squared (Overall):           9.495e-06\n",
      "Time:                           23:19:30   Log-likelihood                -8.902e+04\n",
      "Cov. Estimator:               Unadjusted                                           \n",
      "                                           F-statistic:                      0.4561\n",
      "Entities:                            696   P-value                           0.4995\n",
      "Avg Obs:                          69.016   Distribution:                 F(1,48033)\n",
      "Min Obs:                          11.000                                           \n",
      "Max Obs:                          121.00   F-statistic (robust):             0.4561\n",
      "                                           P-value                           0.4995\n",
      "Time periods:                        121   Distribution:                 F(1,48033)\n",
      "Avg Obs:                          396.98                                           \n",
      "Min Obs:                          86.000                                           \n",
      "Max Obs:                          629.00                                           \n",
      "                                                                                   \n",
      "                                  Parameter Estimates                                  \n",
      "=======================================================================================\n",
      "                     Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   2.0573     0.0072     285.83     0.0000      2.0432      2.0714\n",
      "running_count_event    -0.0002     0.0002    -0.6753     0.4995     -0.0006      0.0003\n",
      "=======================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "endog = df_OLS_ndc_gp['ln_price_per_unit_adj']\n",
    "exog_vars = ['running_count_event']\n",
    "exog = sm.add_constant(df_OLS_ndc_gp[exog_vars])\n",
    "\n",
    "mod = PanelOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Regression for probability of entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['second_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df_temp['second_entrance'] = df_temp['second_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date'] = df_temp['date'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                      4.81e-07\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2692\n",
      "No. Observations:              193557   R-squared (Within):            4.417e-05\n",
      "Date:                Tue, Mar 22 2022   R-squared (Overall):            4.81e-07\n",
      "Time:                        21:50:43   Log-likelihood                 -6.99e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      0.0931\n",
      "Entities:                        2886   P-value                           0.7603\n",
      "Avg Obs:                       67.068   Distribution:                F(1,193555)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       612.00   F-statistic (robust):             0.0931\n",
      "                                        P-value                           0.7603\n",
      "Time periods:                     121   Distribution:                F(1,193555)\n",
      "Avg Obs:                       1599.6                                           \n",
      "Min Obs:                       148.00                                           \n",
      "Max Obs:                       5578.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.1415     0.0042     33.362     0.0000      0.1332      0.1498\n",
      "ln_total_amount_reimbursed_adj_sum -9.189e-05     0.0003    -0.3051     0.7603     -0.0007      0.0005\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['third_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 3 else 0)\n",
    "df_temp['third_entrance'] = df_temp['third_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                        0.0011\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2013\n",
      "No. Observations:              225135   R-squared (Within):              -0.0011\n",
      "Date:                Fri, Mar 18 2022   R-squared (Overall):              0.0011\n",
      "Time:                        12:24:48   Log-likelihood                -7.836e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      242.12\n",
      "Entities:                        3012   P-value                           0.0000\n",
      "Avg Obs:                       74.746   Distribution:                F(1,225133)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       1255.0   F-statistic (robust):             242.12\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                     121   Distribution:                F(1,225133)\n",
      "Avg Obs:                       1860.6                                           \n",
      "Min Obs:                       145.00                                           \n",
      "Max Obs:                       6558.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.0775     0.0038     20.188     0.0000      0.0699      0.0850\n",
      "ln_total_amount_reimbursed_adj_sum     0.0042     0.0003     15.560     0.0000      0.0037      0.0047\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
