{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # removing some warnings\n",
    "pd.set_option('display.max_columns', None) # display all columns in DF\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "import seaborn as sns\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import dtale\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "from linearmodels import PooledOLS\n",
    "from linearmodels import PanelOLS\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_org = pd.read_csv('raw_consolidation_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg_org.loc[df_reg_org['is_original_packager'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg_org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "523938"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        567\n",
      "1  1991-04-01        591\n",
      "2  1991-07-01        604\n",
      "3  1991-10-01        606\n",
      "4  1992-01-01        637\n",
      "Quarterly Average:  4330.06611570248\n",
      "Total:  7214\n",
      "Total (generic_name):  2117\n",
      "Total (labeler):  839\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())\n",
    "print('Total (generic_name): ', df_temp['generic_name'].nunique())\n",
    "print('Total (labeler): ', df_temp['labeler_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing labeller that are original packager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523938\n",
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg_org))\n",
    "df_reg = df_reg_org.loc[df_reg_org['is_original_packager'] == True]\n",
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning order of entrance for each unique drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.sort_values(by = ['unique_id', 'date', 'marketing_category'], ascending = [False, True, False], ignore_index = True) # Sorting\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'labeler_name'], keep = 'first') # Finding the first entrance for each labeller \n",
    "\n",
    "df_temp['labeler_name_count'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'labeler_name', 'labeler_name_count']], df_reg, on = ['unique_id', 'labeler_name'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for first entrance and NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['labeler_name_count'] == 1) & (df_reg['marketing_category'] == 'NDA')] # Filtering\n",
    "\n",
    "df_temp = df_temp.sort_values(by = ['date', 'unique_id'], ascending = [True, False], ignore_index = True) # Sorting\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['first_nda'] = 1 # Adding dummy\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'first_nda']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['first_nda'] = df_reg['first_nda'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug where the first entrance is not a NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['first_nda'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_start'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_start']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_second_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_second_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_second_entrance'] = df_reg['running_count_from_second_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from third entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 3]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_third_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_third_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_third_entrance'] = df_reg['running_count_from_third_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from fourth entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 4]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_fourth_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_fourth_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_fourth_entrance'] = df_reg['running_count_from_fourth_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a total count of the labelers at the start (to exclude unique drug with multiple labelers from the start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['running_count_from_start'] == 1)]\n",
    "          \n",
    "df_temp = df_temp.groupby(['unique_id'])['first_nda'].sum()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.rename(columns = {\"first_nda\": \"number_of_first_entrance\"})\n",
    "\n",
    "df_temp = df_temp.loc[(df_temp['number_of_first_entrance'] > 1)]\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'number_of_first_entrance']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['number_of_first_entrance'] = df_reg['number_of_first_entrance'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug which has multiple entrances at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['number_of_first_entrance'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of generic labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'labeler_name', 'labeler_name_count']]\n",
    "\n",
    "df_temp = df_temp.groupby(['date', 'unique_id'])\n",
    "\n",
    "df_temp = df_temp.max()\n",
    "\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_generics'] = df_temp['labeler_name_count'] - 1 # Minus by one because org. labeler do not count\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_generics']], df_reg, on = ['date', 'unique_id'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of substitutes labelers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking pharm class to obtain EPC and MoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(df_reg[['unique_id', 'pharm_class']])\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'pharm_class'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['pharm_class'])\n",
    "df_temp['pharm_class'] = df_temp['pharm_class'].apply(literal_eval)\n",
    "df_temp = df_temp.explode('pharm_class')\n",
    "\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class'].apply(lambda x: str(x)[-5:])\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class_type'].str.replace(r'[][]', '', regex=True)\n",
    "\n",
    "df_temp_EPC = df_temp[df_temp['pharm_class_type'] == 'EPC']\n",
    "df_temp_MoA = df_temp[df_temp['pharm_class_type'] == 'MoA']\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.rename(columns = {\"pharm_class\": \"pharm_class_EPC\"})\n",
    "df_temp_MoA = df_temp_MoA.rename(columns = {\"pharm_class\": \"pharm_class_MoA\"})\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.drop_duplicates(subset = ['unique_id', 'pharm_class_EPC'])\n",
    "df_temp_MoA = df_temp_MoA.drop_duplicates(subset = ['unique_id', 'pharm_class_MoA'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_temp_EPC, df_temp_MoA,  on = 'unique_id', how = 'left')\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.dropna(subset = ['pharm_class_EPC'])\n",
    "df_pharm_class_type = df_pharm_class_type.dropna(subset = ['pharm_class_MoA'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openFDA_NDC = pd.read_csv('raw_openFDA_NDC_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_openFDA_NDC.drop_duplicates(subset = ['unique_id'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['route'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_pharm_class_type, df_temp[['unique_id', 'route']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a unique id for substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharm_class_type['unique_substitute'] = df_pharm_class_type['pharm_class_EPC'].astype(str) + '-' + df_pharm_class_type['route'].astype(str) + '-' + df_pharm_class_type['pharm_class_MoA'].astype(str)\n",
    "df_pharm_class_type = df_pharm_class_type[['unique_id', 'unique_substitute']]\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.drop_duplicates(subset = ['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_reg, df_pharm_class_type[['unique_id', 'unique_substitute']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['date', 'unique_substitute'])['unique_id'].agg('nunique')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_unique_substitute'] = df_temp['unique_id'] - 1\n",
    "\n",
    "df_reg = pd.merge(df_reg, df_temp[['date', 'unique_substitute', 'running_count_unique_substitute']],  on = ['date', 'unique_substitute'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count where the first entrance is the starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the running count from the start for unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'running_count_from_start', 'running_count_from_second_entrance']]\n",
    "\n",
    "df_temp['col_temp'] = df_temp['running_count_from_second_entrance'].map(lambda x: True if (x == 1.0)  else False)\n",
    "\n",
    "df_temp = df_temp[df_temp['col_temp'] == True]\n",
    "df_temp = df_temp.drop(columns=['col_temp'])\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])\n",
    "df_temp = df_temp.rename(columns = {\"running_count_from_start\": \"col_temp\"})\n",
    "df_temp = df_temp[['unique_id', 'col_temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'col_temp']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculationg the running count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['col_temp'] = df_reg['col_temp'].fillna(0)\n",
    "df_reg['col_temp'] = df_reg['running_count_from_start'] - df_reg['col_temp']\n",
    "\n",
    "df_reg['running_count_event'] = df_reg['col_temp'].where(df_reg['col_temp'] != df_reg['running_count_from_start'])\n",
    "\n",
    "df_reg = df_reg.drop(columns=['col_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for the number of quarter before and after first entrance (running_count_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['unique_id']).agg({'running_count_event': [np.min,np.max]})\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.droplevel(0, axis=1) \n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"\": \"unique_id\", \"amin\": \"min_quarter_before_second_entrance\", \"amax\": \"max_quarter_before_second_entrance\"})\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'min_quarter_before_second_entrance', 'max_quarter_before_second_entrance']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for 2006 (change in Medicare which affect Medicaid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['dummy_2006'] = df_reg['year'].apply(lambda x: 1 if x == 2006 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the quarterly total amount reimbursed and units reimbursed for all labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'units_reimbursed_sum', 'total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the generic labelers' share of quarterly total amount reimbursed and units reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"generic_units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"generic_total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'generic_units_reimbursed_sum', 'generic_total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['generic_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'] / df_reg['units_reimbursed_sum']\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'] / df_reg['total_amount_reimbursed_adj_sum']\n",
    "\n",
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_share_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_share_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv('output_regression_org.csv', sep = '~', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv('output_regression_org.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        148\n",
      "1  1991-04-01        159\n",
      "2  1991-07-01        165\n",
      "3  1991-10-01        165\n",
      "4  1992-01-01        181\n",
      "Quarterly Average:  1599.6446280991736\n",
      "Total:  2886\n",
      "Total (generic_name):  1155\n",
      "Total (labeler):  595\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())\n",
    "print('Total (generic_name): ', df_temp['generic_name'].nunique())\n",
    "print('Total (labeler): ', df_temp['labeler_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for generic paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_reg\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on orig. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118723"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_temp[df_temp['labeler_name_count'] == 1]\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48035"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing data NaN in running_count_event\n",
    "df_temp = df_temp.dropna(subset = ['running_count_event'])\n",
    "\n",
    "# Select the min. number of quarter before and after the entrance entrance\n",
    "df_temp = df_temp[df_temp['min_quarter_before_second_entrance'] <= -10] # including drugs with 10 or more quarters \n",
    "df_temp = df_temp[df_temp['max_quarter_before_second_entrance'] >= 10]\n",
    "\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of price per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_price_per_unit_adj'] = np.log(df_temp['price_per_unit_adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date_int'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date_int'] = df_temp['date_int'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS_ndc_gp = df_temp.set_index(['unique_id', 'date_int'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            PanelOLS Estimation Summary                            \n",
      "===================================================================================\n",
      "Dep. Variable:     ln_price_per_unit_adj   R-squared:                     9.495e-06\n",
      "Estimator:                      PanelOLS   R-squared (Between):             -0.0067\n",
      "No. Observations:                  48035   R-squared (Within):              -0.0021\n",
      "Date:                   Thu, Mar 24 2022   R-squared (Overall):           9.495e-06\n",
      "Time:                           23:19:30   Log-likelihood                -8.902e+04\n",
      "Cov. Estimator:               Unadjusted                                           \n",
      "                                           F-statistic:                      0.4561\n",
      "Entities:                            696   P-value                           0.4995\n",
      "Avg Obs:                          69.016   Distribution:                 F(1,48033)\n",
      "Min Obs:                          11.000                                           \n",
      "Max Obs:                          121.00   F-statistic (robust):             0.4561\n",
      "                                           P-value                           0.4995\n",
      "Time periods:                        121   Distribution:                 F(1,48033)\n",
      "Avg Obs:                          396.98                                           \n",
      "Min Obs:                          86.000                                           \n",
      "Max Obs:                          629.00                                           \n",
      "                                                                                   \n",
      "                                  Parameter Estimates                                  \n",
      "=======================================================================================\n",
      "                     Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "---------------------------------------------------------------------------------------\n",
      "const                   2.0573     0.0072     285.83     0.0000      2.0432      2.0714\n",
      "running_count_event    -0.0002     0.0002    -0.6753     0.4995     -0.0006      0.0003\n",
      "=======================================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "endog = df_OLS_ndc_gp['ln_price_per_unit_adj']\n",
    "exog_vars = ['running_count_event']\n",
    "exog = sm.add_constant(df_OLS_ndc_gp[exog_vars])\n",
    "\n",
    "mod = PanelOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for probability of entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['second_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df_temp['second_entrance'] = df_temp['second_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date'] = df_temp['date'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                      4.81e-07\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2692\n",
      "No. Observations:              193557   R-squared (Within):            4.417e-05\n",
      "Date:                Tue, Mar 22 2022   R-squared (Overall):            4.81e-07\n",
      "Time:                        21:50:43   Log-likelihood                 -6.99e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      0.0931\n",
      "Entities:                        2886   P-value                           0.7603\n",
      "Avg Obs:                       67.068   Distribution:                F(1,193555)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       612.00   F-statistic (robust):             0.0931\n",
      "                                        P-value                           0.7603\n",
      "Time periods:                     121   Distribution:                F(1,193555)\n",
      "Avg Obs:                       1599.6                                           \n",
      "Min Obs:                       148.00                                           \n",
      "Max Obs:                       5578.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.1415     0.0042     33.362     0.0000      0.1332      0.1498\n",
      "ln_total_amount_reimbursed_adj_sum -9.189e-05     0.0003    -0.3051     0.7603     -0.0007      0.0005\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['third_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 3 else 0)\n",
    "df_temp['third_entrance'] = df_temp['third_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                        0.0011\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2013\n",
      "No. Observations:              225135   R-squared (Within):              -0.0011\n",
      "Date:                Fri, Mar 18 2022   R-squared (Overall):              0.0011\n",
      "Time:                        12:24:48   Log-likelihood                -7.836e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      242.12\n",
      "Entities:                        3012   P-value                           0.0000\n",
      "Avg Obs:                       74.746   Distribution:                F(1,225133)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       1255.0   F-statistic (robust):             242.12\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                     121   Distribution:                F(1,225133)\n",
      "Avg Obs:                       1860.6                                           \n",
      "Min Obs:                       145.00                                           \n",
      "Max Obs:                       6558.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.0775     0.0038     20.188     0.0000      0.0699      0.0850\n",
      "ln_total_amount_reimbursed_adj_sum     0.0042     0.0003     15.560     0.0000      0.0037      0.0047\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
