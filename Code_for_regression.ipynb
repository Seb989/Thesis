{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None # removing some warnings\n",
    "pd.set_option('display.max_columns', None) # display all columns in DF\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdate\n",
    "import seaborn as sns\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "import dtale\n",
    "\n",
    "import time\n",
    "import datetime as dt\n",
    "\n",
    "from linearmodels import PooledOLS\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg_org = pd.read_csv('raw_consolidation_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing labeller that are original packager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "523938\n",
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg_org))\n",
    "df_reg = df_reg_org.loc[df_reg_org['is_original_packager'] == True]\n",
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning order of entrance for each unique drug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.sort_values(by = ['unique_id', 'date', 'marketing_category'], ascending = [False, True, False], ignore_index = True) # Sorting\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'labeler_name'], keep = 'first') # Finding the first entrance for each labeller \n",
    "\n",
    "df_temp['labeler_name_count'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'labeler_name', 'labeler_name_count']], df_reg, on = ['unique_id', 'labeler_name'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for first entrance and NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['labeler_name_count'] == 1) & (df_reg['marketing_category'] == 'NDA')] # Filtering\n",
    "\n",
    "df_temp = df_temp.sort_values(by = ['date', 'unique_id'], ascending = [True, False], ignore_index = True) # Sorting\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id'], keep = 'first') # Removing dublicates\n",
    "\n",
    "df_temp['first_nda'] = 1 # Adding dummy\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'first_nda']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['first_nda'] = df_reg['first_nda'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499057\n"
     ]
    }
   ],
   "source": [
    "print(len(df_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug where the first entrance is not a NDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['first_nda'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_start'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_start']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_second_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_second_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_second_entrance'] = df_reg['running_count_from_second_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from third entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 3]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_third_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_third_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_third_entrance'] = df_reg['running_count_from_third_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count for each unique drug from fourth entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 4]\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['date', 'unique_id']) # Removing dublicates\n",
    "df_temp = df_temp[['date', 'unique_id']]\n",
    "df_temp = df_temp.sort_values(by = ['unique_id', 'date'])\n",
    "\n",
    "df_temp['running_count_from_fourth_entrance'] = df_temp.groupby((df_temp['unique_id'] != df_temp['unique_id'].shift(1)).cumsum()).cumcount() + 1 # Running count for each drung\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_from_fourth_entrance']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['running_count_from_fourth_entrance'] = df_reg['running_count_from_fourth_entrance'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202233"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a total count of the labelers at the start (to exclude unique drug with multiple labelers from the start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.loc[(df_reg['running_count_from_start'] == 1)]\n",
    "          \n",
    "df_temp = df_temp.groupby(['unique_id'])['first_nda'].sum()\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.rename(columns = {\"first_nda\": \"number_of_first_entrance\"})\n",
    "\n",
    "df_temp = df_temp.loc[(df_temp['number_of_first_entrance'] > 1)]\n",
    "\n",
    "df_reg = pd.merge(df_temp[['unique_id', 'number_of_first_entrance']], df_reg, on = ['unique_id'], how = 'right') # Merging with reg. data\n",
    "\n",
    "df_reg['number_of_first_entrance'] = df_reg['number_of_first_entrance'].fillna(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unique drug which has multiple entrances at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.loc[(df_reg['number_of_first_entrance'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of generic labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'labeler_name', 'labeler_name_count']]\n",
    "\n",
    "df_temp = df_temp.groupby(['date', 'unique_id'])\n",
    "\n",
    "df_temp = df_temp.max()\n",
    "\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_generics'] = df_temp['labeler_name_count'] - 1 # Minus by one because org. labeler do not count\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'running_count_generics']], df_reg, on = ['date', 'unique_id'], how = 'right') # Merging with org. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count of substitutes labelers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking pharm class to obtain EPC and MoA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.DataFrame(df_reg[['unique_id', 'pharm_class']])\n",
    "\n",
    "df_temp = df_temp.drop_duplicates(subset = ['unique_id', 'pharm_class'])\n",
    "\n",
    "df_temp = df_temp.dropna(subset = ['pharm_class'])\n",
    "df_temp['pharm_class'] = df_temp['pharm_class'].apply(literal_eval)\n",
    "df_temp = df_temp.explode('pharm_class')\n",
    "\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class'].apply(lambda x: str(x)[-5:])\n",
    "df_temp['pharm_class_type'] = df_temp['pharm_class_type'].str.replace(r'[][]', '', regex=True)\n",
    "\n",
    "df_temp_EPC = df_temp[df_temp['pharm_class_type'] == 'EPC']\n",
    "df_temp_MoA = df_temp[df_temp['pharm_class_type'] == 'MoA']\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.rename(columns = {\"pharm_class\": \"pharm_class_EPC\"})\n",
    "df_temp_MoA = df_temp_MoA.rename(columns = {\"pharm_class\": \"pharm_class_MoA\"})\n",
    "\n",
    "df_temp_EPC = df_temp_EPC.drop_duplicates(subset = ['unique_id', 'pharm_class_EPC'])\n",
    "df_temp_MoA = df_temp_MoA.drop_duplicates(subset = ['unique_id', 'pharm_class_MoA'])\n",
    "\n",
    "df_pharm_class_type = pd.merge(df_temp_EPC, df_temp_MoA,  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_openFDA_NDC = pd.read_csv('raw_openFDA_NDC_data.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_openFDA_NDC.drop_duplicates(subset = ['unique_id'])\n",
    "df_pharm_class_type = pd.merge(df_pharm_class_type, df_temp[['unique_id', 'route']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a unique id for substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pharm_class_type['unique_substitute'] = df_pharm_class_type['pharm_class_EPC'].astype(str) + '-' + df_pharm_class_type['route'].astype(str) + '-' + df_pharm_class_type['pharm_class_MoA'].astype(str)\n",
    "df_pharm_class_type = df_pharm_class_type[['unique_id', 'unique_substitute']]\n",
    "\n",
    "df_pharm_class_type = df_pharm_class_type.drop_duplicates(subset = ['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_reg, df_pharm_class_type[['unique_id', 'unique_substitute']],  on = 'unique_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating number of substitutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['date', 'unique_substitute'])['unique_id'].count()\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp['running_count_unique_substitute'] = df_temp['unique_id'] - 1\n",
    "\n",
    "df_reg = pd.merge(df_reg, df_temp[['date', 'unique_substitute', 'running_count_unique_substitute']],  on = ['date', 'unique_substitute'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a running count where the first entrance is the starting point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the running count from the start for unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[['date', 'unique_id', 'running_count_from_start', 'running_count_from_second_entrance']]\n",
    "\n",
    "df_temp['col_temp'] = df_temp['running_count_from_second_entrance'].map(lambda x: True if (x == 1.0)  else False)\n",
    "\n",
    "df_temp = df_temp[df_temp['col_temp'] == True]\n",
    "df_temp = df_temp.drop(columns=['col_temp'])\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])\n",
    "df_temp = df_temp.rename(columns = {\"running_count_from_start\": \"col_temp\"})\n",
    "df_temp = df_temp[['unique_id', 'col_temp']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'col_temp']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculationg the running count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['col_temp'] = df_reg['col_temp'].fillna(0)\n",
    "df_reg['col_temp'] = df_reg['running_count_from_start'] - df_reg['col_temp']\n",
    "\n",
    "df_reg['running_count_event'] = df_reg['col_temp'].where(df_reg['col_temp'] != df_reg['running_count_from_start'])\n",
    "\n",
    "df_reg = df_reg.drop(columns=['col_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning a dummy for the number of quarter before and after first entrance (running_count_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.groupby(['unique_id']).agg({'running_count_event': [np.min,np.max]})\n",
    "df_temp = df_temp.reset_index()\n",
    "df_temp = df_temp.droplevel(0, axis=1) \n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"\": \"unique_id\", \"amin\": \"min_quarter_before_second_entrance\", \"amax\": \"max_quarter_before_second_entrance\"})\n",
    "df_temp = df_temp.drop_duplicates(subset=['unique_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging with org. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.merge(df_temp[['unique_id', 'min_quarter_before_second_entrance', 'max_quarter_before_second_entrance']], df_reg, on = ['unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the quarterly total amount reimbursed and units reimbursed for all labelers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'units_reimbursed_sum', 'total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the generic labelers' share of quarterly total amount reimbursed and units reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg[df_reg['labeler_name_count'] >= 2]\n",
    "\n",
    "df_temp = df_temp.set_index(['date', 'unique_id']).groupby(level = ['date', 'unique_id'])[['units_reimbursed', 'total_amount_reimbursed_adj']].agg('sum')\n",
    "df_temp = df_temp.reset_index()\n",
    "\n",
    "df_temp = df_temp.rename(columns = {\"units_reimbursed\": \"generic_units_reimbursed_sum\", \"total_amount_reimbursed_adj\": \"generic_total_amount_reimbursed_adj_sum\"})\n",
    "\n",
    "df_reg = pd.merge(df_temp[['date', 'unique_id', 'generic_units_reimbursed_sum', 'generic_total_amount_reimbursed_adj_sum']], df_reg, on = ['date', 'unique_id',], how = 'right')\n",
    "\n",
    "df_reg['generic_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_units_reimbursed_sum'] / df_reg['units_reimbursed_sum']\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_total_amount_reimbursed_adj_sum'] / df_reg['total_amount_reimbursed_adj_sum']\n",
    "\n",
    "df_reg['generic_share_units_reimbursed_sum'] = df_reg['generic_share_units_reimbursed_sum'].fillna(0)\n",
    "df_reg['generic_share_total_amount_reimbursed_adj_sum'] = df_reg['generic_share_total_amount_reimbursed_adj_sum'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg.to_csv('output_regression_org.csv', sep = '~', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.read_csv('output_regression_org.csv', sep = '~')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting number of unique drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabel:           date  unique_id\n",
      "0  1991-01-01        148\n",
      "1  1991-04-01        159\n",
      "2  1991-07-01        165\n",
      "3  1991-10-01        165\n",
      "4  1992-01-01        181\n",
      "Quarterly Average:  1599.6446280991736\n",
      "Total:  2886\n",
      "Total (generic_name):  1155\n"
     ]
    }
   ],
   "source": [
    "df_temp_count = df_temp.groupby(['date'])['unique_id'].count()\n",
    "df_temp_count = df_temp_count.reset_index()\n",
    "print('Tabel: ', df_temp_count.head())\n",
    "print('Quarterly Average: ', df_temp_count['unique_id'].mean())\n",
    "print('Total: ', df_temp['unique_id'].nunique())\n",
    "print('Total (generic_name): ', df_temp['generic_name'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for generic paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "193557"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_reg\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on orig. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122378"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_temp = df_temp[df_temp['marketing_category'] == \"NDA\"]\n",
    "len(df_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of price per unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_price_per_unit_adj'] = np.log(df_temp['price_per_unit_adj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the share of units reimbursed for the org. labeler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['org_share_units_reimbursed_sum'] = 1 - df_temp['generic_share_units_reimbursed_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date_int'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date_int'] = df_temp['date_int'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS_ndc_gp = df_temp.set_index(['unique_id', 'date_int'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                                              object\n",
       "generic_units_reimbursed_sum                     float64\n",
       "generic_total_amount_reimbursed_adj_sum          float64\n",
       "units_reimbursed_sum                             float64\n",
       "total_amount_reimbursed_adj_sum                  float64\n",
       "                                                  ...   \n",
       "running_count_event                              float64\n",
       "generic_share_units_reimbursed_sum               float64\n",
       "generic_share_total_amount_reimbursed_adj_sum    float64\n",
       "ln_price_per_unit_adj                            float64\n",
       "org_share_units_reimbursed_sum                   float64\n",
       "Length: 70, dtype: object"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_OLS_ndc_gp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS_ndc_gp['running_count_generics'] = pd.to_numeric(df_OLS_ndc_gp['running_count_generics'], errors='coerce').fillna(0, downcast='infer')\n",
    "df_OLS_ndc_gp['running_count_unique_substitute'] = pd.to_numeric(df_OLS_ndc_gp['running_count_unique_substitute'], errors='coerce').fillna(0, downcast='infer')\n",
    "df_OLS_ndc_gp['org_share_units_reimbursed_sum'] = pd.to_numeric(df_OLS_ndc_gp['org_share_units_reimbursed_sum'], errors='coerce').fillna(0, downcast='infer')\n",
    "df_OLS_ndc_gp['running_count_from_second_entrance'] = pd.to_numeric(df_OLS_ndc_gp['running_count_from_second_entrance'], errors='coerce').fillna(0, downcast='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            PooledOLS Estimation Summary                           \n",
      "===================================================================================\n",
      "Dep. Variable:     ln_price_per_unit_adj   R-squared:                        0.0137\n",
      "Estimator:                     PooledOLS   R-squared (Between):             -0.0339\n",
      "No. Observations:                 122378   R-squared (Within):              -0.0858\n",
      "Date:                   Wed, Mar 23 2022   R-squared (Overall):              0.0137\n",
      "Time:                           12:29:33   Log-likelihood                -2.722e+05\n",
      "Cov. Estimator:               Unadjusted                                           \n",
      "                                           F-statistic:                      425.15\n",
      "Entities:                           2886   P-value                           0.0000\n",
      "Avg Obs:                          42.404   Distribution:                F(4,122373)\n",
      "Min Obs:                          1.0000                                           \n",
      "Max Obs:                          190.00   F-statistic (robust):             425.15\n",
      "                                           P-value                           0.0000\n",
      "Time periods:                        121   Distribution:                F(4,122373)\n",
      "Avg Obs:                          1011.4                                           \n",
      "Min Obs:                          147.00                                           \n",
      "Max Obs:                          2509.0                                           \n",
      "                                                                                   \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  2.3951     0.0345     69.357     0.0000      2.3274      2.4628\n",
      "running_count_generics                 0.0722     0.0064     11.353     0.0000      0.0597      0.0847\n",
      "running_count_unique_substitute       -0.0009     0.0002    -5.3554     0.0000     -0.0012     -0.0006\n",
      "org_share_units_reimbursed_sum        -0.1824     0.0351    -5.1960     0.0000     -0.2512     -0.1136\n",
      "running_count_from_second_entrance    -0.0269     0.0008    -35.415     0.0000     -0.0283     -0.0254\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "endog = df_OLS_ndc_gp['ln_price_per_unit_adj']\n",
    "exog_vars = ['running_count_generics', 'running_count_unique_substitute', 'org_share_units_reimbursed_sum', 'running_count_from_second_entrance']\n",
    "exog = sm.add_constant(df_OLS_ndc_gp[exog_vars])\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression for probability of entrance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['second_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 2 else 0)\n",
    "df_temp['second_entrance'] = df_temp['second_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the format of the date to a integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['date'] = df_temp['date'].str.replace('-', '')\n",
    "df_temp['date'] = df_temp['date'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                      4.81e-07\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2692\n",
      "No. Observations:              193557   R-squared (Within):            4.417e-05\n",
      "Date:                Tue, Mar 22 2022   R-squared (Overall):            4.81e-07\n",
      "Time:                        21:50:43   Log-likelihood                 -6.99e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      0.0931\n",
      "Entities:                        2886   P-value                           0.7603\n",
      "Avg Obs:                       67.068   Distribution:                F(1,193555)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       612.00   F-statistic (robust):             0.0931\n",
      "                                        P-value                           0.7603\n",
      "Time periods:                     121   Distribution:                F(1,193555)\n",
      "Avg Obs:                       1599.6                                           \n",
      "Min Obs:                       148.00                                           \n",
      "Max Obs:                       5578.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.1415     0.0042     33.362     0.0000      0.1332      0.1498\n",
      "ln_total_amount_reimbursed_adj_sum -9.189e-05     0.0003    -0.3051     0.7603     -0.0007      0.0005\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign a dummy for second entrance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['third_entrance'] = df_temp['labeler_name_count'].apply(lambda x: 1 if x == 3 else 0)\n",
    "df_temp['third_entrance'] = df_temp['third_entrance'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the log of the sum of total amount reimbursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp['ln_total_amount_reimbursed_adj_sum'] = np.log(df_temp['total_amount_reimbursed_adj_sum'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_OLS = df_temp.set_index(['unique_id', 'date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimating the regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          PooledOLS Estimation Summary                          \n",
      "================================================================================\n",
      "Dep. Variable:        second_entrance   R-squared:                        0.0011\n",
      "Estimator:                  PooledOLS   R-squared (Between):             -0.2013\n",
      "No. Observations:              225135   R-squared (Within):              -0.0011\n",
      "Date:                Fri, Mar 18 2022   R-squared (Overall):              0.0011\n",
      "Time:                        12:24:48   Log-likelihood                -7.836e+04\n",
      "Cov. Estimator:            Unadjusted                                           \n",
      "                                        F-statistic:                      242.12\n",
      "Entities:                        3012   P-value                           0.0000\n",
      "Avg Obs:                       74.746   Distribution:                F(1,225133)\n",
      "Min Obs:                       1.0000                                           \n",
      "Max Obs:                       1255.0   F-statistic (robust):             242.12\n",
      "                                        P-value                           0.0000\n",
      "Time periods:                     121   Distribution:                F(1,225133)\n",
      "Avg Obs:                       1860.6                                           \n",
      "Min Obs:                       145.00                                           \n",
      "Max Obs:                       6558.0                                           \n",
      "                                                                                \n",
      "                                         Parameter Estimates                                          \n",
      "======================================================================================================\n",
      "                                    Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------------------------------\n",
      "const                                  0.0775     0.0038     20.188     0.0000      0.0699      0.0850\n",
      "ln_total_amount_reimbursed_adj_sum     0.0042     0.0003     15.560     0.0000      0.0037      0.0047\n",
      "======================================================================================================\n"
     ]
    }
   ],
   "source": [
    "exog_vars = ['ln_total_amount_reimbursed_adj_sum']\n",
    "exog = sm.add_constant(df_OLS[exog_vars])\n",
    "endog = df_OLS['second_entrance']\n",
    "\n",
    "mod = PooledOLS(endog, exog)\n",
    "pooled_res = mod.fit()\n",
    "print(pooled_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
